{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for training used on the provided dataset\n",
    "\n",
    "\n",
    "Using the NVIDIA architecture\n",
    "This is mainly used for looking at the potential preprocessing steps, model architecture etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Cropping2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import sklearn\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_label = \"data/driving_log.csv\"\n",
    "path_img = \"data/IMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(path_label=\"data/driving_log.csv\"):\n",
    "    df = pd.read_csv(path_label)\n",
    "    labels = df[\"steering\"].values\n",
    "    print(\"Got labels\")\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(path_img=\"data/IMG\"):\n",
    "    images = []\n",
    "    fnames = os.listdir(path_img)\n",
    "    for fname in fnames:\n",
    "        # only use CENTER images first\n",
    "        if fname.startswith(\"center\"):\n",
    "            img = plt.imread(os.path.join(path_img, fname))\n",
    "            images.append(img)\n",
    "    images = np.array(images)\n",
    "    print(\"Got images\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))  # normalize\n",
    "    # add cropping\n",
    "    model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "    model.add(Conv2D(24,(5,5), strides=(2,2), activation=\"relu\"))\n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation=\"relu\"))\n",
    "    model.add(Conv2D(48, (5,5), strides=(2,2), activation=\"relu\"))\n",
    "    model.add(Conv2D(64, (3,3), strides=(1,1), activation=\"relu\"))\n",
    "    model.add(Conv2D(64, (3,3), strides=(1,1), activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got labels\n"
     ]
    }
   ],
   "source": [
    "# labels = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "samples = samples[1:]\n",
    "        \n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "def flip_image(image, angle):\n",
    "    image_flipped = np.fliplr(image)\n",
    "    angle_flipped = -angle\n",
    "    return image_flipped, angle_flipped\n",
    "\n",
    "\n",
    "def generator(samples, batch_size=32, flip_images=True, add_left_images=True, add_right_images=True):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        correction = 0.2\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = 'data/IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = plt.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                \n",
    "                if add_left_images:\n",
    "                    left_img_name = 'data/IMG/'+batch_sample[1].split('/')[-1]\n",
    "                    left_image = plt.imread(left_img_name)\n",
    "                    left_angle = center_angle + correction\n",
    "                    images.append(left_image)\n",
    "                    angles.append(left_angle)\n",
    "                \n",
    "                if add_right_images:\n",
    "                    right_img_name = 'data/IMG/'+batch_sample[2].split('/')[-1]\n",
    "                    right_image = plt.imread(right_img_name)\n",
    "                    right_angle = center_angle - correction\n",
    "                    images.append(right_image)\n",
    "                    angles.append(right_angle)\n",
    "                \n",
    "                # add image augmentation by flipping *each* image\n",
    "                if flip_images:\n",
    "                    if center_angle!=0: # no need to flip image if steering wheel angle is 0!\n",
    "                        image_flipped, angle_flipped = flip_image(center_image, center_angle)\n",
    "                        images.append(image_flipped)\n",
    "                        angles.append(angle_flipped)\n",
    "                        \n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our batch size\n",
    "batch_size=128\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = get_labels()\n",
    "#X_train = get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.mse,\n",
    "              optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "51/51 [==============================] - 107s 2s/step - loss: 0.0303 - val_loss: 0.0197\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 77s 2s/step - loss: 0.0185 - val_loss: 0.0172\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 76s 1s/step - loss: 0.0172 - val_loss: 0.0165\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 69s 1s/step - loss: 0.0165 - val_loss: 0.0159\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 71s 1s/step - loss: 0.0159 - val_loss: 0.0162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a0802c198>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(X_train, y_train, validation_split=0.2, batch_size=128, epochs=5, shuffle=True)\n",
    "model.fit_generator(train_generator, steps_per_epoch=np.ceil(len(train_samples)/batch_size), \\\n",
    "            validation_data=validation_generator, validation_steps=np.ceil(len(validation_samples)/batch_size), \\\n",
    "            epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"model.h5\")\n",
    "model.save(\"model.h5\")\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook model.ipynb to script\n",
      "[NbConvertApp] Writing 6224 bytes to model.py\n"
     ]
    }
   ],
   "source": [
    "! jupyter nbconvert --to script model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDos for first step\n",
    "\n",
    "# write generator for iterative loading of images\n",
    "# add regularization stuff (batch_norm, dropout)\n",
    "# train and save model\n",
    "# deploy model and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Experimentations:\n",
    "\n",
    "\n",
    "- different processing strategies in lambda layer\n",
    "- Image augmentation (flipping)\n",
    "- cropping images (top and bottom)\n",
    "- use left and right images for recovery\n",
    "- modify model architecture\n",
    "- iterative, \"transfer\" learning approach (see https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/Behavioral+Cloning+Cheatsheet+-+CarND.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
