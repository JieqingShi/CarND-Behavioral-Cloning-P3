{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for training used on the provided dataset\n",
    "\n",
    "\n",
    "Using the NVIDIA architecture\n",
    "This is mainly used for looking at the potential preprocessing steps, model architecture etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Cropping2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_label = \"data/driving_log.csv\"\n",
    "path_img = \"data/IMG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(path_label=\"data/driving_log.csv\"):\n",
    "    df = pd.read_csv(path_label)\n",
    "    labels = df[\"steering\"].values\n",
    "    print(\"Got labels\")\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(path_img=\"data/IMG\"):\n",
    "    images = []\n",
    "    fnames = os.listdir(path_img)\n",
    "    for fname in fnames:\n",
    "        # only use CENTER images first\n",
    "        if fname.startswith(\"center\"):\n",
    "            img = plt.imread(os.path.join(path_img, fname))\n",
    "            images.append(img)\n",
    "    images = np.array(images)\n",
    "    print(\"Got images\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))  # normalize\n",
    "    # add cropping\n",
    "    model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "    model.add(Conv2D(24,(5,5), strides=(2,2), activation=\"relu\"))\n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation=\"relu\"))\n",
    "    model.add(Conv2D(48, (5,5), strides=(2,2), activation=\"relu\"))\n",
    "    model.add(Conv2D(64, (3,3), strides=(1,1), activation=\"relu\"))\n",
    "    model.add(Conv2D(64, (3,3), strides=(1,1), activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got labels\n",
      "Got images\n"
     ]
    }
   ],
   "source": [
    "y_train = get_labels()\n",
    "X_train = get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.mse,\n",
    "              optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6428 samples, validate on 1608 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, batch_size=128, epochs=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model.h5\")\n",
    "model.save(\"model.h5\")\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDos for first step\n",
    "\n",
    "# write generator for iterative loading of images\n",
    "# add regularization stuff (batch_norm, dropout)\n",
    "# train and save model\n",
    "# deploy model and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Experimentations:\n",
    "\n",
    "\n",
    "- different processing strategies in lambda layer\n",
    "- Image augmentation (flipping)\n",
    "- cropping images (top and bottom)\n",
    "- use left and right images for recovery\n",
    "- modify model architecture\n",
    "- iterative, \"transfer\" learning approach (see https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/Behavioral+Cloning+Cheatsheet+-+CarND.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
